{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca6b435f-b79e-4634-8cd7-4e2ac205a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1acbfc20-448b-466e-a63a-487b860f5b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.12/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.12/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.local/lib/python3.12/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.local/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/tljh/user/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/tljh/user/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/tljh/user/lib/python3.12/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.local/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in ./.local/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.12/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in ./.local/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: packaging in /opt/tljh/user/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/tljh/user/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/tljh/user/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/tljh/user/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/tljh/user/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/tljh/user/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/tljh/user/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/tljh/user/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/tljh/user/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/tljh/user/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/tljh/user/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/tljh/user/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf2d22c3-991b-4500-97ce-05fb85fe74d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ca51c5fb0343ec8ecc88c29bdca7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89fbb28da7041db8b7c060b10837582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757793179fbc48a4b607075a6db5cdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8dccb2364544aa9b65c56bd76f1518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00003.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f662b8ac721e4e389f954aa60075389b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7eaa6dd0df40b7857b2e13dd858f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664eeb32dfc147f0874b7263358aae34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb45ee746de494eba6b3f174c3708bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd4b28c1796499b9f33252b186b3224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6c7a3d4ae24aa9a3d6736f1d4af201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train\")\n",
    "dataset = dataset.remove_columns(['article', 'id'])  # remove the 'article' and 'id' fields as we will not be using them in our task\n",
    "from numpy.random import default_rng\n",
    "\n",
    "rng = default_rng(seed=42)\n",
    "# create a list of non-repeated indices of size 10000 and use it to select the training samples\n",
    "select_idx = rng.choice(len(dataset), size=10000, replace=False)\n",
    "dataset = dataset.filter(lambda example, idx: idx in select_idx, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1da6404-8d23-45f4-807c-d5fe07ef1e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['highlights'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30d4f7a-5964-4d7c-9188-17990c5f02f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .\",\n",
       " \"David Nalbandian won Madrid Masters after beating top seed Roger Federer .\\nThe Argentine triumphed 1-6 6-3 6-3 against the Swiss defending champion .\\nHe became third man to beat world's three top players en route to a title .\",\n",
       " 'Bus driver, tractor-trailer trucker injured in 3-vehicle crash, AP reports .\\nBus crossed median, hit pickup truck, then 18-wheeler, killing 3 .\\nAll lanes of I-40 closed for 13 miles east of Forrest City, Arkansas .\\nDriver of the pickup truck and two bus passengers killed, police say .',\n",
       " 'North Korean crew recaptures hijacked vessel .\\nNavy says two pirates killed, five captured; three from crew injured .\\nUSS Arleigh Burke enters Somali territorial waters to pursue other pirates .\\nPirates aboard hijacked Golden Nori carrying highly flammable benzene .',\n",
       " 'Detainees file suit against ICE, allege they were injected with drugs .\\nOne detainee tells CNN: \"What they did to me was very, very bad\"\\nICE says 1,073 detainees have had \"medical escorts\" since 2003 .\\nSen. Lieberman vows to investigate further; spokesman calls charges \"troubling\"',\n",
       " \"Glasgow derby between Celtic and Rangers on Wednesday is postponed .\\nDecision made as a mark of respect after death of ex-player Phil O'Donnell .\\nMotherwell's home game against Celtic next Sunday was already called off .\",\n",
       " 'Head of Iraqi Red Crescent says parents abandoning their kids at alarming rates .\\nSometimes he wonders: \"Oh my God, how are we going to solve it?\"\\nThe greatest concern is the long-term effect on an entire generation .\\n\"Trauma of what\\'s happening to those children is enormous\"',\n",
       " \"At least 10 people have died in torrential rains in Ecuador, officials say .\\nAuthorities say the rains are the worst in a quarter century .\\nCivil defense officials say more than 10,000 families have been affected .\\nEcuador's president declares state of emergency, orders army, police to help .\",\n",
       " 'Democratic senators will hold short \"pro forma\" sessions over the holiday break .\\nSessions usually under one minute long .\\nMove prevents President Bush from making recess appointments .\\nBush refused to withdraw one controversial nominee after Democratic offer .',\n",
       " 'GAO: Investigators took advantage of \"weaknesses in TSA procedures\"\\nGAO: Those \"weaknesses\" were not detailed for security reasons .\\nGAO said terrorists using same items could seriously compromise a flight .\\nTransportation Security Administration: Checkpoints only part of total security .']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the first articles\n",
    "dataset['highlights'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2183f92-1b11-4cf8-b235-f7eb81337ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the prefix \"xxxxx -- \" from all article text\n",
    "\n",
    "sentences = [x.replace(\"\\n\", \" \") for x in dataset['highlights']]\n",
    "sentences = [x for x in sentences if len(x.split()) <= 500]  # remove any text which, after has tokens length > 500\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe038d30-7fd1-4c24-bedd-e5ad35e5b7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lower case, and clean all the symbols\n",
    "sentences = [x.lower() for x in sentences]\n",
    "sentences = [re.sub(\"[.,!?\\\\-]\", '', x) for x in sentences]\n",
    "#making vocabs - numericalization\n",
    "word_list = list(set(\" \".join(sentences).split()))\n",
    "word2id   = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3}\n",
    "for i, w in enumerate(word_list):\n",
    "    word2id[w] = i + 4 #reserve the first 0-3 for CLS, PAD\n",
    "\n",
    "vocab_size = len(word2id)\n",
    "id2word    = {i:w for i, w  in enumerate(word2id)}\n",
    "token_list = [[word2id[word] for word in sentence.split()] for sentence in sentences]\n",
    "len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e72ab25-aadb-4bcf-b9de-21c400505391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1024]),\n",
       " torch.Size([8, 1024]),\n",
       " torch.Size([8, 15]),\n",
       " torch.Size([8, 15]),\n",
       " tensor([0, 0, 0, 0, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_batch(batch_size, max_mask, max_len):\n",
    "    batch = []\n",
    "    half_batch_size = batch_size // 2\n",
    "    positive = negative = 0\n",
    "    while positive != half_batch_size or negative != half_batch_size:\n",
    "\n",
    "        #randomly choose two sentence\n",
    "        tokens_a_index, tokens_b_index = np.random.randint(len(sentences), size=2)\n",
    "        tokens_a, tokens_b            = token_list[tokens_a_index], token_list[tokens_b_index]\n",
    "\n",
    "        #1. token embedding - add CLS and SEP\n",
    "        input_ids = [word2id['[CLS]']] + tokens_a + [word2id['[SEP]']] + tokens_b + [word2id['[SEP]']]\n",
    "\n",
    "        #2. segment embedding - which sentence is 0 and 1\n",
    "        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        n_pred = min(max_mask, max(1, int(round(len(input_ids) * 0.15))))\n",
    "        #get all the pos excluding CLS and SEP\n",
    "        candidates_masked_pos = [i for i, token in enumerate(input_ids) if token != word2id['[CLS]']\n",
    "                                 and token != word2id['[SEP]']]\n",
    "        np.random.shuffle(candidates_masked_pos)\n",
    "        masked_tokens, masked_pos = [], []\n",
    "        #simply loop and mask accordingly\n",
    "        for pos in candidates_masked_pos[:n_pred]:\n",
    "            masked_pos.append(pos)\n",
    "            masked_tokens.append(input_ids[pos])\n",
    "            rand_val = np.random.random()\n",
    "            if rand_val < 0.1:  #10% replace with random token\n",
    "                index = np.random.randint(4, vocab_size - 1)  # random token should not involve [PAD], [CLS], [SEP], [MASK]\n",
    "                input_ids[pos] = word2id[id2word[index]]\n",
    "            elif rand_val < 0.8:  #80 replace with [MASK]\n",
    "                input_ids[pos] = word2id['[MASK]']\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        #4. pad the sentence to the max length\n",
    "        n_pad = max_len - len(input_ids)\n",
    "        input_ids.extend([0] * n_pad)\n",
    "        segment_ids.extend([0] * n_pad)\n",
    "\n",
    "        #5. pad the mask tokens to the max length\n",
    "        if max_mask > n_pred:\n",
    "            n_pad = max_mask - n_pred\n",
    "            masked_tokens.extend([0] * n_pad)\n",
    "            masked_pos.extend([0] * n_pad)\n",
    "\n",
    "        #6. check whether is positive or negative\n",
    "        if tokens_a_index + 1 == tokens_b_index and positive < half_batch_size:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True])\n",
    "            positive += 1\n",
    "        elif tokens_a_index + 1 != tokens_b_index and negative < half_batch_size:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False])\n",
    "            negative += 1\n",
    "\n",
    "    return batch\n",
    "batch_size = 8\n",
    "max_mask   = 15 #even though it does not reach 15% yet....maybe you can set this threshold\n",
    "max_len    = 1024 #maximum length that my transformer will accept.....all sentence will be padded\n",
    "batch = make_batch(batch_size, max_mask, max_len)\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n",
    "input_ids.shape, segment_ids.shape, masked_tokens.shape, masked_pos.shape, isNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a83b19d-e34d-43a2-acd3-60c01921fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, n_segments, d_model, device):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.tok_embed = nn.Embedding(vocab_size, d_model)  # token embedding\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)      # position embedding\n",
    "        self.seg_embed = nn.Embedding(n_segments, d_model)  # segment(token type) embedding\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x, seg):\n",
    "        #x, seg: (bs, len)\n",
    "        seq_len = x.size(1)\n",
    "        pos = torch.arange(seq_len, dtype=torch.long).to(self.device)\n",
    "        pos = pos.unsqueeze(0).expand_as(x)  # (len,) -> (bs, len)\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "831603ea-87f5-4886-97e0-baf097e0b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k, device):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1).to(device)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc238360-8593-4e96-98c4-327c701bf5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(get_attn_pad_mask(input_ids, input_ids, 'cpu').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "933827b2-90be-4269-8889-e1cf927b8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, n_heads, d_model, d_ff, d_k, device):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(n_heads, d_model, d_k, device)\n",
    "        self.pos_ffn       = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34bef1e5-503f-49e9-bb1b-a3ce45516452",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k, device):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([d_k])).to(device)\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / self.scale # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "584a0f03-7b4d-41c2-838a-86a2f5405118",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, d_model, d_k, device):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_k\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_model, self.d_v * n_heads)\n",
    "        self.device = device\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
    "\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
    "\n",
    "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        context, attn = ScaledDotProductAttention(self.d_k, self.device)(q_s, k_s, v_s, attn_mask)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v) # context: [batch_size x len_q x n_heads * d_v]\n",
    "        output = nn.Linear(self.n_heads * self.d_v, self.d_model, device=self.device)(context)\n",
    "        return nn.LayerNorm(self.d_model, device=self.device)(output + residual), attn # output: [batch_size x len_q x d_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "287294fe-9692-4ba4-ac7f-29aec8a853ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch_size, len_seq, d_model) -> (batch_size, len_seq, d_ff) -> (batch_size, len_seq, d_model)\n",
    "        return self.fc2(F.gelu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "060adc03-e6c1-4052-a24a-97d6f5b880dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, n_layers, n_heads, d_model, d_ff, d_k, n_segments, vocab_size, max_len, device):\n",
    "        super(BERT, self).__init__()\n",
    "        ## Saving the params\n",
    "        self.params = {'n_layers': n_layers, 'n_heads': n_heads, 'd_model': d_model,\n",
    "                       'd_ff': d_ff, 'd_k': d_k, 'n_segments': n_segments,\n",
    "                       'vocab_size': vocab_size, 'max_len': max_len}\n",
    "        self.embedding = Embedding(vocab_size, max_len, n_segments, d_model, device)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(n_heads, d_model, d_ff, d_k, device) for _ in range(n_layers)])\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.activ = nn.Tanh()\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.classifier = nn.Linear(d_model, 2)\n",
    "        # decoder is shared with embedding layer\n",
    "        embed_weight = self.embedding.tok_embed.weight\n",
    "        n_vocab, n_dim = embed_weight.size()\n",
    "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False)\n",
    "        self.decoder.weight = embed_weight\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input_ids, segment_ids, masked_pos):\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids, self.device)\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "        # output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]\n",
    "\n",
    "        # 1. predict next sentence\n",
    "        # it will be decided by first token(CLS)\n",
    "        h_pooled   = self.activ(self.fc(output[:, 0])) # [batch_size, d_model]\n",
    "        logits_nsp = self.classifier(h_pooled) # [batch_size, 2]\n",
    "\n",
    "        # 2. predict the masked token\n",
    "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1)) # [batch_size, max_pred, d_model]\n",
    "        h_masked = torch.gather(output, 1, masked_pos) # masking position [batch_size, max_pred, d_model]\n",
    "        h_masked  = self.norm(F.gelu(self.linear(h_masked)))\n",
    "        logits_lm = self.decoder(h_masked) + self.decoder_bias # [batch_size, max_pred, n_vocab]\n",
    "\n",
    "        return logits_lm, logits_nsp\n",
    "\n",
    "    def get_last_hidden_state(self, input_ids, segment_ids):\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids, self.device)\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9ee1e58-786f-44c8-af53-9a3dba42ec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d53c6f89-74dd-42a3-bf95-86e8e5d56c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:28<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "n_layers = 6    # number of Encoder of Encoder Layer\n",
    "n_heads  = 8    # number of heads in Multi-Head Attention\n",
    "d_model  = 768  # Embedding Size\n",
    "d_ff = 768 * 4  # 4*d_model, FeedForward dimension\n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "n_segments = 2\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 4\n",
    "max_mask   = 15\n",
    "max_len    = 1024\n",
    "num_epoch = 10\n",
    "num_step = 100  # 100 num_steps * 4 batch_size = 400 pairs of sentences\n",
    "\n",
    "model = BERT(n_layers, n_heads, d_model, d_ff, d_k, n_segments, vocab_size, max_len, device).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "batch = [make_batch(batch_size, max_mask, max_len) for i in tqdm(range(num_step))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f156c87-29ef-4496-a00e-2edaf120c260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 loss = 63.172860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 loss = 25.727003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 loss = 16.797755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 loss = 13.385530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 loss = 11.649365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 loss = 10.497042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 loss = 9.793736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 loss = 9.324909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 loss = 9.040294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 loss = 8.823236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for step in tqdm(range(num_step)):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch[step]))\n",
    "        input_ids = input_ids.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        masked_tokens = masked_tokens.to(device)\n",
    "        masked_pos = masked_pos.to(device)\n",
    "        isNext = isNext.to(device)\n",
    "        logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)\n",
    "        #logits_lm: (bs, max_mask, vocab_size) ==> (6, 5, 34)\n",
    "        #logits_nsp: (bs, yes/no) ==> (6, 2)\n",
    "\n",
    "        #1. mlm loss\n",
    "        #logits_lm.transpose: (bs, vocab_size, max_mask) vs. masked_tokens: (bs, max_mask)\n",
    "        loss_lm = criterion(logits_lm.transpose(1, 2), masked_tokens) # for masked LM\n",
    "        loss_lm = (loss_lm.float()).mean()\n",
    "        #2. nsp loss\n",
    "        #logits_nsp: (bs, 2) vs. isNext: (bs, )\n",
    "        loss_nsp = criterion(logits_nsp, isNext) # for sentence classification\n",
    "\n",
    "        #3. combine loss\n",
    "        loss = loss_lm + loss_nsp\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch:', '%02d' % (epoch+1), 'loss =', '{:.6f}'.format(epoch_loss / num_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a62ef2a-7d05-4ccb-a617-2b504574e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "save_path = 'bert.pt'\n",
    "torch.save([model.params, model.state_dict()], save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf77fb6e-a078-4cf4-9bfd-3910cec80090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model and all its hyperparameters\n",
    "params, state = torch.load(save_path)\n",
    "model = BERT(**params, device=device).to(device)\n",
    "model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "387edd75-8d06-48bb-99ea-8b5791b89c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'french', 'president', 'francois', '[MASK]', 'larkings', '[MASK]', \"country's\", 'socialists', 'are', 'in', 'a', 'strong', 'position', 'despite', 'this', 'hollande', 'has', 'made', 'little', 'progress', 'since', 'his', 'election', 'says', '[MASK]', 'gaffney', 'gaffney:', 'hollande', '\"like', 'necrophiliac', '[MASK]', 'bunny', 'in', '[MASK]', 'swelled', 'of', 'economic', 'reality', 'president', 'must', 'act', 'now', 'and', 'act', 'decisively', 'to', 'make', 'france', 'admired', 'again', 'says', 'gaffney', '[SEP]', 'short', 'film', 'shows', 'interview', 'with', 'gang', 'member', 'called', 'shouta', 'directed', 'by', 'luke', 'huxham', 'who', 'wanted', '[MASK]', 'show', 'modern', 'face', 'of', 'yakuza', 'shouta', 'has', '[MASK]', \"'business\", \"interests'\", 'headbutting', 'us', 'and', '[MASK]', '[SEP]']\n",
      "masked tokens (words) :  ['to', 'stunned', 'and', 'asia', 'the', 'france', 'various', 'in', 'hollande', 'john', 'a', 'the', 'headlights\"', '[PAD]', '[PAD]']\n",
      "masked tokens list :  [33247, 103, 23779, 34604, 28347, 2211, 22020, 39516, 40189, 11777, 28935, 28347, 39798, 0, 0]\n",
      "predicted masked tokens (words) :  ['to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to']\n",
      "predicted masked tokens list :  [33247, 33247, 33247, 33247, 33247, 33247, 33247, 33247, 33247, 33247, 33247, 33247, 33247, 33247, 33247]\n",
      "1\n",
      "isNext :  False\n",
      "predict isNext :  True\n"
     ]
    }
   ],
   "source": [
    "# Predict mask tokens ans isNext\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(batch[0][0]))\n",
    "input_ids = input_ids.to(device)\n",
    "segment_ids = segment_ids.to(device)\n",
    "masked_tokens = masked_tokens.to(device)\n",
    "masked_pos = masked_pos.to(device)\n",
    "isNext = isNext.to(device)\n",
    "print([id2word[w.item()] for w in input_ids[0] if id2word[w.item()] != '[PAD]'])\n",
    "\n",
    "logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)\n",
    "#logits_lm:  (1, max_mask, vocab_size) ==> (1, 5, 34)\n",
    "#logits_nsp: (1, yes/no) ==> (1, 2)\n",
    "\n",
    "#predict masked tokens\n",
    "#max the probability along the vocab dim (2), [1] is the indices of the max, and [0] is the first value\n",
    "logits_lm = logits_lm.data.cpu().max(2)[1][0].data.numpy()\n",
    "#note that zero is padding we add to the masked_tokens\n",
    "print('masked tokens (words) : ',[id2word[pos.item()] for pos in masked_tokens[0]])\n",
    "print('masked tokens list : ',[pos.item() for pos in masked_tokens[0]])\n",
    "print('predicted masked tokens (words) : ',[id2word[pos.item()] for pos in logits_lm])\n",
    "print('predicted masked tokens list : ', [pos for pos in logits_lm])\n",
    "\n",
    "#predict nsp\n",
    "logits_nsp = logits_nsp.data.cpu().max(1)[1][0].data.numpy()\n",
    "print(logits_nsp)\n",
    "print('isNext : ', True if isNext else False)\n",
    "print('predict isNext : ',True if logits_nsp else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e03026-d72d-4897-a368-cfe6c8e2e54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b405a841-00be-4f8b-8ed3-00d1c1849d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04ca3f-6823-4d1e-a842-38d3290339e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826b942-2af8-4961-9a4b-f5ba23fe2485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847b8e5-10e4-4af8-aee8-d24c51a18f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eeb63420-63d9-4775-8463-00233719fd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import re\n",
    "from   random import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set GPU device\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c58900a-dc98-4fa2-b539-3b882bfe63af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'premise': Value(dtype='string', id=None), 'hypothesis': Value(dtype='string', id=None), 'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None), 'idx': Value(dtype='int32', id=None)}\n",
      "{'premise': Value(dtype='string', id=None), 'hypothesis': Value(dtype='string', id=None), 'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None)}\n",
      "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])\n",
      "['premise', 'hypothesis', 'label']\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# Load the datasets\n",
    "snli = datasets.load_dataset('snli')\n",
    "mnli = datasets.load_dataset('glue', 'mnli')\n",
    "\n",
    "# Check the features of both datasets\n",
    "print(mnli['train'].features)\n",
    "print(snli['train'].features)\n",
    "\n",
    "# List the column names of the mnli dataset\n",
    "print(mnli.column_names.keys())  # This will output the keys correctly\n",
    "\n",
    "# Remove 'idx' column from each dataset split\n",
    "for column_name in mnli.column_names.keys():\n",
    "    mnli[column_name] = mnli[column_name].remove_columns('idx')\n",
    "\n",
    "# Verify that 'idx' column is removed\n",
    "print(mnli['train'].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f446ec41-a3ad-4fa6-9fb9-93231c9534c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([-1,  0,  1,  2]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])\n",
    "#snli also have -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fecae574-7d13-47ec-818a-32ef2420579d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c6e0119cb14da7ad109ac88c3edac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848eee114e3d4255bb13bdd2b95eebd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b92e5a8fd94dd8aaf95a65aba9dadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/550152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# there are -1 values in the label feature, these are where no class could be decided so we remove\n",
    "snli = snli.filter(\n",
    "    lambda x: 0 if x['label'] == -1 else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b20a7ad-2a9d-4505-9e06-b81d86e933a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([0, 1, 2]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])\n",
    "#snli also have -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59a5dd17-ed14-4b94-8eb8-708f845c3794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have your two DatasetDict objects named snli and mnli\n",
    "from datasets import DatasetDict\n",
    "# Merge the two DatasetDict objects\n",
    "raw_dataset = DatasetDict({\n",
    "    'train': datasets.concatenate_datasets([snli['train'], mnli['train']]).shuffle(seed=55).select(list(range(1000))),\n",
    "    'test': datasets.concatenate_datasets([snli['test'], mnli['test_mismatched']]).shuffle(seed=55).select(list(range(100))),\n",
    "    'validation': datasets.concatenate_datasets([snli['validation'], mnli['validation_mismatched']]).shuffle(seed=55).select(list(range(1000)))\n",
    "})\n",
    "#remove .select(list(range(1000))) in order to use full dataset\n",
    "# Now, merged_dataset_dict contains the combined datasets from snli and mnli\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a5b296b-452c-476e-b732-7bd48ee8bdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a9a8116e084448a167df332e00b216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2507c447e2645769f82cd00b2d134ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced0158a5afd4ee0a8a813f59c4d0e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdc76fb6c6d435d8d9c0c95bd42cab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3d299d10c24e5d86a4c839ef940368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67495c39-3570-4344-94d5-c9eaa5c79f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a2ebcd2e8d4686a4a41784a47ca9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96fd53a7b0944142821e691ac4b16cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a527f94a41f34c2ba125613e24d308f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_seq_length = 1024\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    padding = 'max_length'\n",
    "    # Tokenize the premise\n",
    "    premise_result = tokenizer(\n",
    "        examples['premise'], padding=padding, max_length=max_seq_length, truncation=True)\n",
    "    #num_rows, max_seq_length\n",
    "    # Tokenize the hypothesis\n",
    "    hypothesis_result = tokenizer(\n",
    "        examples['hypothesis'], padding=padding, max_length=max_seq_length, truncation=True)\n",
    "    #num_rows, max_seq_length\n",
    "    # Extract labels\n",
    "    labels = examples[\"label\"]\n",
    "    #num_rows\n",
    "    return {\n",
    "        \"premise_input_ids\": premise_result[\"input_ids\"],\n",
    "        \"premise_attention_mask\": premise_result[\"attention_mask\"],\n",
    "        \"hypothesis_input_ids\": hypothesis_result[\"input_ids\"],\n",
    "        \"hypothesis_attention_mask\": hypothesis_result[\"attention_mask\"],\n",
    "        \"labels\" : labels\n",
    "    }\n",
    "\n",
    "tokenized_datasets = raw_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['premise','hypothesis','label'])\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d9e532b-682e-4c3d-a1d3-3a33790eab9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ee82af2-fd82-4d61-a5d6-a63c8d5b9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# initialize the dataloader\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets['train'],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets['validation'],\n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets['test'],\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d8f4378-77fe-469d-b8c1-ca3ec29c712b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1024])\n",
      "torch.Size([4, 1024])\n",
      "torch.Size([4, 1024])\n",
      "torch.Size([4, 1024])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch['premise_input_ids'].shape)\n",
    "    print(batch['premise_attention_mask'].shape)\n",
    "    print(batch['hypothesis_input_ids'].shape)\n",
    "    print(batch['hypothesis_attention_mask'].shape)\n",
    "    print(batch['labels'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39227ebe-ae16-4782-aae3-3ab811a25507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter-st125050'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d822fd1b-0777-4588-b015-9cd38c845bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert import BERT\n",
    "\n",
    "# load the model and all its hyperparameters\n",
    "load_path = 'bert.pt'\n",
    "params, state = torch.load(load_path)\n",
    "model = BERT(**params, device=device).to(device)\n",
    "model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75617959-473c-4564-8186-7130e131709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mean pooling function\n",
    "def mean_pool(token_embeds, attention_mask):\n",
    "    # reshape attention_mask to cover 768-dimension embeddings\n",
    "    in_mask = attention_mask.unsqueeze(-1).expand(\n",
    "        token_embeds.size()\n",
    "    ).float()\n",
    "    # perform mean-pooling but exclude padding tokens (specified by in_mask)\n",
    "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(\n",
    "        in_mask.sum(1), min=1e-9\n",
    "    )\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1335f6ca-9cae-4f92-9ba0-b7c7072c6171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125050/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    }
   ],
   "source": [
    "def configurations(u,v):\n",
    "    # build the |u-v| tensor\n",
    "    uv = torch.sub(u, v)   # batch_size,hidden_dim\n",
    "    uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
    "\n",
    "    # concatenate u, v, |u-v|\n",
    "    x = torch.cat([u, v, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
    "    return x\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    dot_product = np.dot(u, v)\n",
    "    norm_u = np.linalg.norm(u)\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    similarity = dot_product / (norm_u * norm_v)\n",
    "    return similarity\n",
    "classifier_head = torch.nn.Linear(768*3, 3).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "optimizer_classifier = torch.optim.Adam(classifier_head.parameters(), lr=2e-5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# and setup a warmup for the first ~10% steps\n",
    "total_steps = int(len(raw_dataset) / batch_size)\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "\t\toptimizer, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")\n",
    "\n",
    "# then during the training loop we update the scheduler per step\n",
    "scheduler.step()\n",
    "\n",
    "scheduler_classifier = get_linear_schedule_with_warmup(\n",
    "\t\toptimizer_classifier, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")\n",
    "\n",
    "# then during the training loop we update the scheduler per step\n",
    "scheduler_classifier.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2345d957-efcf-4324-9a1a-4fa5d7d66e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9dee37d0e6e4bb496c28c26f6641d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | loss = 9.920999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a135837ae24691ac0dcced65257cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | loss = 6.557790\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5528632bd1454bd59d9c5afb8b214b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | loss = 3.834829\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93ec09eebb14d85ae4fda55defb5f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | loss = 0.626869\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0060ec70c24d2d808b3948cddb7699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | loss = 1.282690\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "num_epoch = 5\n",
    "# 1 epoch should be enough, increase if wanted\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    classifier_head.train()\n",
    "    # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, leave=True)):\n",
    "        # zero all gradients on each new step\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_classifier.zero_grad()\n",
    "\n",
    "        # prepare batches and more all to the active device\n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        segment_ids = torch.zeros(batch_size, max_seq_length, dtype=torch.int32).to(device)  # each input contains only one sentence hence we define them all as sentence '0'\n",
    "        label = batch['labels'].to(device)\n",
    "\n",
    "        # extract token embeddings from BERT at last_hidden_state\n",
    "        u_last_hidden_state = model.get_last_hidden_state(inputs_ids_a, segment_ids)\n",
    "        v_last_hidden_state = model.get_last_hidden_state(inputs_ids_b, segment_ids)\n",
    "\n",
    "        # u_last_hidden_state = u.last_hidden_state # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "        # v_last_hidden_state = v.last_hidden_state # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "         # get the mean pooled vectors\n",
    "        u_mean_pool = mean_pool(u_last_hidden_state, attention_a) # batch_size, hidden_dim\n",
    "        v_mean_pool = mean_pool(v_last_hidden_state, attention_b) # batch_size, hidden_dim\n",
    "\n",
    "        # build the |u-v| tensor\n",
    "        uv = torch.sub(u_mean_pool, v_mean_pool)   # batch_size,hidden_dim\n",
    "        uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
    "\n",
    "        # concatenate u, v, |u-v|\n",
    "        x = torch.cat([u_mean_pool, v_mean_pool, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
    "\n",
    "        # process concatenated tensor through classifier_head\n",
    "        x = classifier_head(x) #batch_size, classifer\n",
    "\n",
    "        # calculate the 'softmax-loss' between predicted and true label\n",
    "        loss = criterion(x, label)\n",
    "\n",
    "        # using loss, calculate gradients and then optimizerize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_classifier.step()\n",
    "\n",
    "        scheduler.step() # update learning rate scheduler\n",
    "        scheduler_classifier.step()\n",
    "\n",
    "    print(f'Epoch: {epoch + 1} | loss = {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45199277-bd88-440d-99b0-d6162829a6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity: 0.9992\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "classifier_head.eval()\n",
    "total_similarity = 0\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        # prepare batches and more all to the active device\n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        segment_ids = torch.zeros(batch_size, max_seq_length, dtype=torch.int32).to(device)\n",
    "        label = batch['labels'].to(device)\n",
    "\n",
    "        # extract token embeddings from BERT at last_hidden_state\n",
    "        u = model.get_last_hidden_state(inputs_ids_a, segment_ids)  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "        v = model.get_last_hidden_state(inputs_ids_b, segment_ids)  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "        # get the mean pooled vectors\n",
    "        u_mean_pool = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1) # batch_size, hidden_dim\n",
    "        v_mean_pool = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1) # batch_size, hidden_dim\n",
    "\n",
    "        similarity_score = cosine_similarity(u_mean_pool, v_mean_pool)\n",
    "        total_similarity += similarity_score\n",
    "\n",
    "average_similarity = total_similarity / len(eval_dataloader)\n",
    "print(f\"Average Cosine Similarity: {average_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3897bdc6-bfb7-4fb2-87e1-b243bc7fe59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.local/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.local/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "Downloading scipy-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 scipy-1.15.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3af71ddc-5912-40e4-9efb-5ab1ed89d20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9995\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(model, tokenizer, sentence_a, sentence_b, device):\n",
    "    # Tokenize and convert sentences to input IDs and attention masks\n",
    "    inputs_a = tokenizer(sentence_a, return_tensors='pt', max_length=max_seq_length, truncation=True, padding='max_length').to(device)\n",
    "    inputs_b = tokenizer(sentence_b, return_tensors='pt', max_length=max_seq_length, truncation=True, padding='max_length').to(device)\n",
    "\n",
    "    # Move input IDs and attention masks to the active device\n",
    "    inputs_ids_a = inputs_a['input_ids']\n",
    "    attention_a = inputs_a['attention_mask']\n",
    "    inputs_ids_b = inputs_b['input_ids']\n",
    "    attention_b = inputs_b['attention_mask']\n",
    "    segment_ids = torch.zeros(1, max_seq_length, dtype=torch.int32).to(device)\n",
    "\n",
    "    # Extract token embeddings from BERT\n",
    "    u = model.get_last_hidden_state(inputs_ids_a, segment_ids)  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "    v = model.get_last_hidden_state(inputs_ids_b, segment_ids)  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "    # u = model(inputs_ids_a, attention_mask=attention_a)[0]  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "    # v = model(inputs_ids_b, attention_mask=attention_b)[0]  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "    # Get the mean-pooled vectors\n",
    "    u = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
    "    v = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity_score = cosine_similarity(u.reshape(1, -1), v.reshape(1, -1))[0, 0]\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "# Example usage:\n",
    "sentence_a = 'Your contribution helped make it possible for us to provide our students with a quality education.'\n",
    "sentence_b = \"Your contributions were of no help with our students' education.\"\n",
    "similarity = calculate_similarity(model, tokenizer, sentence_a, sentence_b, device)\n",
    "print(f\"Cosine Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3df6343-aa69-4050-b281-d4afb1676527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f1263b2c-87fc-4634-8abb-75306356a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['Your contribution helped make it possible for us to provide our students with a quality education.', \"Your contributions were of no help with our students' education.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "706f3936-972a-4e05-afec-98cbd6cc1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b698fb2-4dca-4028-8e17-dfea5094a4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.5604592561721802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['Your contribution helped make it possible for us to provide our students with a quality education.', \n",
    "             \"Your contributions were of no help with our students' education.\"]\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Extract sentence embeddings using mean pooling\n",
    "sent_a_emb = mean_pooling(model_output, encoded_input['attention_mask'])[0].cpu().numpy()\n",
    "sent_b_emb = mean_pooling(model_output, encoded_input['attention_mask'])[1].cpu().numpy()\n",
    "\n",
    "# Reshape embeddings to 2D arrays (1 sample, embedding_dim)\n",
    "sent_a_emb = sent_a_emb.reshape(1, -1)\n",
    "sent_b_emb = sent_b_emb.reshape(1, -1)\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity = cosine_similarity(sent_a_emb, sent_b_emb)\n",
    "print(f\"Cosine similarity: {similarity[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c948d6-4434-4dfa-b1a2-05ec7fc62c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2e1964-f99a-466d-b7ce-98f3c06006d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69e1855c-2323-4557-b20a-04e4825fb536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 1.0000001192092896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Extract sentence embeddings using mean pooling\n",
    "sent_a_emb = mean_pooling(model_output, encoded_input['attention_mask'])[0].cpu().numpy()\n",
    "sent_b_emb = mean_pooling(model_output, encoded_input['attention_mask'])[1].cpu().numpy()\n",
    "\n",
    "# Reshape embeddings to 2D arrays (1 sample, embedding_dim)\n",
    "sent_a_emb = sent_a_emb.reshape(1, -1)\n",
    "sent_b_emb = sent_b_emb.reshape(1, -1)\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity = cosine_similarity(sent_a_emb, sent_b_emb)\n",
    "print(f\"Cosine similarity: {similarity[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1078ca-9ad3-4402-9433-0b90e94821dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
